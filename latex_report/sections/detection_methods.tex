The Smart Proxy system employs multiple detection methods to identify phishing and malicious websites accurately. This multi-layered approach combines machine learning with traditional pattern analysis to achieve higher detection rates while minimizing false positives.

\section{Machine Learning-Based Detection}

\subsection{Model Architecture}
The system uses an XGBoost gradient boosting framework for phishing detection. XGBoost was selected for its:

\begin{itemize}
    \item High accuracy on structured data
    \item Efficient performance on both training and inference
    \item Robust handling of missing features
    \item Strong resistance to overfitting
\end{itemize}

\subsection{Feature Extraction}
The ML model analyzes various features extracted from URLs and HTML content:

\begin{itemize}
    \item \textbf{URL Features}:
    \begin{itemize}
        \item Domain length and entropy
        \item Number of subdomains and path segments
        \item Presence of suspicious TLDs
        \item URL encoding characteristics
        \item Special character frequency
    \end{itemize}
    
    \item \textbf{HTML Features}:
    \begin{itemize}
        \item Form submission targets
        \item External resource ratios
        \item JavaScript usage patterns
        \item Password field presence without HTTPS
        \item Brand-related keywords
    \end{itemize}
\end{itemize}

\subsection{Confidence Scoring}
The model outputs a probability score between 0 and 1, representing the confidence that a site is phishing:

\begin{lstlisting}[language=Python, caption=ML Prediction Method]
def predict(self, url, html_content):
    """Predict if a URL is a phishing site using the ML model"""
    start = time.time()
    
    # Extract features from URL and HTML
    features = self._extract_features(url, html_content)
    features_array = np.array([list(features.values())])
    
    # Make prediction
    prediction = self.model.predict(features_array)[0]
    probas = self.model.predict_proba(features_array)[0]
    
    # Convert to native Python float for JSON serialization
    confidence = float(probas[1]) * 100  # phishing class probability
    
    return prediction == 1, confidence, float(time.time() - start) * 1000
\end{lstlisting}

A configurable threshold (default: 0.85 or 85\%) determines when to block access. This threshold can be adjusted in the configuration file to balance security with user convenience.

\section{Traditional Pattern Analysis}

Complementing the ML approach, the system performs rule-based analysis of web content:

\subsection{Suspicious Keywords}
The system maintains a list of terms commonly associated with phishing:

\begin{lstlisting}[language=Python, caption=Phishing Keywords]
PHISHING_KEYWORDS = [
    "login", "password", "signin", "account", 
    "bank", "credit", "wallet", "verify", "secure", 
    "authenticate", "paypal", "billing"
]
\end{lstlisting}

\subsection{Malicious JavaScript Detection}
The analyzer scans for potentially dangerous JavaScript patterns:

\begin{lstlisting}[language=Python, caption=Malicious JavaScript Detection]
MALICIOUS_JS_PATTERNS = [
    r"eval\s*\(",                          # Eval usage
    r"document\.write\s*\(",               # Document write
    r"(?:document|window)\.location\s*=\s*['\"][^'\"]*['\"]"  # Redirects
]

# In analyze method
for pattern in self.MALICIOUS_JS_PATTERNS:
    if re.search(pattern, html_content):
        warning = f"Suspicious JavaScript pattern: {pattern}"
        detected_patterns.append(warning)
\end{lstlisting}

\subsection{Hidden Iframe Detection}
Hidden iframes are often used in phishing and malware distribution:

\begin{lstlisting}[language=Python, caption=Hidden Iframe Detection]
# Look for hidden iframes
iframes = re.findall(r"<iframe[^>]*src=['\"]([^'\"]+)['\"]", html_content)
for iframe in iframes:
    if not iframe.startswith(('http://' + domain, 'https://' + domain, '/')):
        warning = f"External iframe from {iframe}"
        detected_patterns.append(warning)
\end{lstlisting}

\subsection{XSS Detection}
The system also scans for potential cross-site scripting attempts:

\begin{lstlisting}[language=Python, caption=XSS Detection]
# Check for potential XSS
xss_scripts = re.findall(self.XSS_PATTERN, html_content)
if len(xss_scripts) > 3:  # Multiple script tags could indicate XSS
    warning = f"Found {len(xss_scripts)} script tags that could be XSS attempts"
    detected_patterns.append(warning)
\end{lstlisting}

\section{Blacklist Integration}

For known malicious domains, the system maintains a blacklist in JSON format:

\begin{lstlisting}[language=Python, caption=Blacklist Checking]
def is_blacklisted(self, host):
    """Check if a host is in the blacklist"""
    # Direct match
    if host in self.blacklist:
        return True
        
    # Check for wildcard matches (*.malicious.com)
    for pattern in self.blacklist:
        if pattern.startswith('*.') and host.endswith(pattern[2:]):
            return True
    
    return False
\end{lstlisting}

\section{Combined Detection Approach}

The system's multi-layered approach provides several advantages:

\begin{itemize}
    \item \textbf{Higher Detection Rate}: Different techniques catch different types of phishing
    \item \textbf{Reduced False Positives}: Sites must trigger multiple indicators to be blocked
    \item \textbf{Adaptation}: Traditional rules can catch new threats before ML model retraining
    \item \textbf{Explainability}: Pattern detection provides clear reasons for blocking
\end{itemize}

This combined approach allows the system to maintain high detection rates while providing users with detailed information about why a particular site was flagged as suspicious.
