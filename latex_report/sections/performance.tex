Performance optimization is crucial for any proxy-based security system, as users expect minimal impact on their browsing experience. This chapter details the strategies implemented to ensure that the Smart Proxy operates efficiently while maintaining robust security protections.

\section{Selective Content Scanning}

Not all web traffic requires the same level of scrutiny. The system implements selective scanning to focus computational resources where they are most needed:

\begin{lstlisting}[language=Python, caption=Selective Content Scanning]
def response(self, flow: http.HTTPFlow) -> None:
    # Skip non-HTML content
    content_type = flow.response.headers.get("content-type", "")
    if not content_type.startswith("text/html"):
        return
        
    # Skip common static resources
    url = flow.request.pretty_url
    path = flow.request.path.lower()
    
    # Skip static resources and API calls
    if any(path.endswith(ext) for ext in self.excluded_extensions):
        return
        
    # Skip small responses (likely not complete HTML)
    if len(flow.response.content) < 500:
        return
        
    # Now perform full analysis...
\end{lstlisting}

The excluded extensions typically include:

\begin{lstlisting}[language=Python]
self.excluded_extensions = [
    '.css', '.js', '.jpg', '.jpeg', '.png', '.gif', '.svg',
    '.woff', '.woff2', '.ttf', '.eot', '.ico', '.xml', 
    '.pdf', '.zip', '.mp4', '.webm', '.mp3', '.wav'
]
\end{lstlisting}

\section{Caching Mechanism}

To avoid redundant processing of frequently visited pages, the system implements a simple caching mechanism:

\begin{lstlisting}[language=Python, caption=Scan Result Caching]
class ScannerAnalyzer:
    def __init__(self):
        # Initialize cache with limited size
        self.cache = {}  # {url: result}
        self.cache_limit = 1000
        
    def analyze(self, url, html_content):
        # Check cache first
        if url in self.cache:
            logging.info(f"[Cache Hit] Using cached result for {url}")
            return self.cache[url]
            
        # Perform analysis...
        result = self._analyze_content(url, html_content)
        
        # Update cache
        if len(self.cache) >= self.cache_limit:
            # Simple LRU: remove oldest item
            self.cache.pop(next(iter(self.cache)))
        self.cache[url] = result
        
        return result
\end{lstlisting}

This simple caching system dramatically improves performance for frequently visited sites while maintaining a reasonable memory footprint.

\section{Efficient Whitelist Checking}

Whitelist checking is implemented using sets for O(1) lookup performance:

\begin{lstlisting}[language=Python, caption=Efficient Whitelist Checking]
def _load_whitelist(self):
    """Load whitelist patterns from whitelist.json"""
    try:
        with open(self.whitelist_path, 'r') as f:
            whitelist_patterns = json.load(f)
            # Convert to set for O(1) lookups
            self.whitelist = set(str(pattern) for pattern in whitelist_patterns)
    except Exception as e:
        logging.error(f"Error loading whitelist: {e}")
        self.whitelist = set()  # Empty set as fallback
        
def _is_whitelisted(self, domain):
    """Check if a domain matches any whitelist pattern"""
    # Direct match - O(1) operation with sets
    if domain in self.whitelist:
        return True
        
    # Check for wildcard matches
    # Note: This is necessarily O(n) where n is the number of whitelist entries
    for pattern in self.whitelist:
        if pattern.startswith('*.') and domain.endswith(pattern[2:]):
            return True
    return False
\end{lstlisting}

\section{Optimized ML Model}

The XGBoost model is optimized for inference speed:

\begin{itemize}
    \item \textbf{Feature Selection}: Only the most predictive features are used
    \item \textbf{Model Pruning}: Tree depth and complexity are limited
    \item \textbf{Lazy Loading}: Model is loaded only when needed
\end{itemize}

\begin{lstlisting}[language=Python, caption=Optimized Model Loading]
class MLPhishingDetector:
    def __init__(self, model_path, brands_path=None):
        self.model = None  # Lazy loading
        self.model_path = model_path
        self.brands_path = brands_path
        self.brands = self._load_brands() if brands_path else set()
        
    def _load_model(self):
        """Load model only when needed"""
        if self.model is None:
            logging.info(f"Loading ML model from {self.model_path}")
            self.model = joblib.load(self.model_path)
            
    def predict(self, url, html_content):
        """Predict if a URL is a phishing site"""
        self._load_model()  # Ensure model is loaded
        
        # Extract features and make prediction...
\end{lstlisting}

\section{Pagination for Large Data Sets}

For interfaces that may need to display large amounts of data, such as the whitelist management page, pagination is implemented:

\begin{lstlisting}[language=Python, caption=Pagination Implementation]
@app.route('/whitelist')
def whitelist_manager():
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 50, type=int)
    search = request.args.get('search', '')
    
    # Convert whitelist set to a sorted list for pagination
    whitelist = list(sorted(traffic_analyzer.whitelist))
    
    # Filter by search term if provided
    if search:
        whitelist = [domain for domain in whitelist 
                    if search.lower() in domain.lower()]
    
    # Calculate pagination values
    total_items = len(whitelist)
    total_pages = math.ceil(total_items / per_page)
    start_idx = (page - 1) * per_page
    end_idx = min(start_idx + per_page, total_items)
    current_items = whitelist[start_idx:end_idx]
\end{lstlisting}

This ensures that even with thousands of whitelist entries, the interface remains responsive and manageable.

\section{Asynchronous Operations}

Where appropriate, operations are performed asynchronously to avoid blocking the user interface:

\begin{lstlisting}[language=JavaScript, caption=Asynchronous AJAX Operations]
// Bulk add domains AJAX call
$("#bulkAddForm").submit(function(e) {
    e.preventDefault();
    
    const domains = $("#bulkDomainInput").val().trim();
    if (!domains) {
        showAlert("Please enter at least one domain", "danger");
        return;
    }
    
    // Show loading indicator
    $("#bulkAddBtn").html('<span class="spinner-border spinner-border-sm"></span> Adding...');
    $("#bulkAddBtn").prop("disabled", true);
    
    // Send AJAX request
    $.post("/whitelist/bulk-add", {domains: domains})
        .done(function(response) {
            showAlert(`Added ${response.added} domains successfully`, "success");
            setTimeout(function() {
                location.reload();
            }, 1500);
        })
        .fail(function(xhr) {
            showAlert("Error: " + xhr.responseJSON.error, "danger");
        })
        .always(function() {
            $("#bulkAddBtn").html('Add Domains');
            $("#bulkAddBtn").prop("disabled", false);
        });
});
\end{lstlisting}

\section{Performance Metrics}

The system tracks and logs performance metrics to identify bottlenecks:

\begin{lstlisting}[language=Python, caption=Performance Metrics Logging]
def analyze(self, url, html_content):
    start_time = time.time()
    
    # Perform analysis...
    
    end_time = time.time()
    analysis_time_ms = (end_time - start_time) * 1000
    
    logging.info(f"Analysis for {url} took {analysis_time_ms:.2f}ms")
    
    result = {
        'is_malicious': is_malicious,
        'detected_patterns': detected_patterns,
        'analysis_time_ms': analysis_time_ms
    }
    
    return result
\end{lstlisting}

These metrics help identify slow components and guide further optimization efforts.

\section{Threading Considerations}

Since mitmproxy uses a multi-threaded architecture, care is taken to ensure thread safety:

\begin{itemize}
    \item Use of thread-local storage where appropriate
    \item Atomic operations for critical data structures
    \item Minimal use of shared state between handlers
\end{itemize}

\section{Configuration-Based Optimization}

The system allows performance tuning via configuration:

\begin{lstlisting}[language=JSON, caption=Performance Configuration]
{
    "ml_model_path": "phishing_xgb_model.pkl",
    "confidence_threshold": 0.85,
    "scan_timeout": 5,  // Maximum seconds for scanning
    "cache_limit": 1000,  // Number of URLs to cache
    "excluded_extensions": [".jpg", ".png", ...],
    "enable_detailed_logging": false  // Reduce logging overhead
}
\end{lstlisting}

These parameters can be adjusted based on the hardware capabilities and user requirements.

\section{Performance Testing Results}

Performance testing revealed the following metrics:

\begin{itemize}
    \item \textbf{Average scanning time}: 120-250ms per HTML page
    \item \textbf{Cache hit ratio}: ~65\% in typical browsing scenarios
    \item \textbf{Memory usage}: 150-250MB for the proxy process
    \item \textbf{Latency overhead}: 50-150ms for HTML content, <5ms for non-HTML
\end{itemize}

These metrics indicate that the system achieves a good balance between security and performance, with minimal impact on the browsing experience for most users.
