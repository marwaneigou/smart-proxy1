This chapter details the technical implementation of the Smart Proxy system, focusing on the key code components and their interactions.

\section{Proxy Implementation}

The proxy functionality is implemented as a custom mitmproxy addon in main.py. The core class \texttt{SmartProxy} handles the interception and processing of web traffic:

\begin{lstlisting}[language=Python, caption=SmartProxy Class Implementation]
class SmartProxy:
    def __init__(self):
        self.ml_detector = MLPhishingDetector(model_path, brands_path)
        self.whitelist = self.load_whitelist()
        self.blacklist = self.load_blacklist()
        self.whitelisted_tabs = {}  # Track trusted tabs {client_id: domain}
        self.bypass_tokens = {}     # Store bypass tokens {token: domain}
        
    def request(self, flow: http.HTTPFlow) -> None:
        # Extract URL and check if it needs scanning
        url = flow.request.pretty_url
        host = flow.request.host
        path = flow.request.path
        client_id = flow.client_conn.id
        
        # Handle bypass requests
        if path.startswith('/bypass'):
            # Process bypass token and redirect user
            # ...
            
        # Check if this tab is trusted for this domain
        if client_id in self.whitelisted_tabs:
            trusted_domain = self.whitelisted_tabs[client_id]
            if host == trusted_domain:
                # Skip scanning for trusted tabs
                return
                
        # Perform blacklist check
        if self.is_blacklisted(host):
            # Generate block page
            # ...
            
    def response(self, flow: http.HTTPFlow) -> None:
        # Only scan HTML content
        if not flow.response.headers.get("content-type", "").startswith("text/html"):
            return
            
        # Extract content for analysis
        html_content = flow.response.content.decode('utf-8', 'ignore')
        url = flow.request.pretty_url
        
        # Perform ML-based phishing detection
        is_phishing, confidence = self.ml_detector.predict(url, html_content)
        
        if is_phishing:
            # Generate ML detection block page with bypass option
            # ...
            
        # Perform traditional pattern analysis
        patterns = self.scanner_analyzer.analyze(url, html_content)
        
        if patterns['is_malicious']:
            # Generate pattern detection block page
            # ...
\end{lstlisting}

\section{Whitelist and Blacklist Management}

Whitelist and blacklist entries are stored in JSON files and loaded during initialization:

\begin{lstlisting}[language=Python, caption=Whitelist Loading and Checking]
def _load_whitelist(self):
    """Load whitelist patterns from whitelist.json"""
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        self.whitelist_path = os.path.join(script_dir, 'whitelist.json')
        
        if os.path.exists(self.whitelist_path):
            with open(self.whitelist_path, 'r') as f:
                whitelist_patterns = json.load(f)
                # Convert to set for faster lookups
                self.whitelist = set(str(pattern) for pattern in whitelist_patterns)
        else:
            # Initialize empty whitelist with default trusted domains
            self.whitelist = set(["google.com", "www.google.com", 
                                "youtube.com", "facebook.com"])
            self.save_whitelist()
    except Exception as e:
        logging.error(f"Error loading whitelist: {e}")

def _is_whitelisted(self, host):
    """Check if a host matches any whitelist pattern"""
    # Direct match
    if host in self.whitelist:
        return True
        
    # Check for wildcard matches (*.example.com)
    for pattern in self.whitelist:
        if pattern.startswith('*.') and host.endswith(pattern[2:]):
            return True
    return False
\end{lstlisting}

\section{Block Page Generation}

When a potentially malicious site is detected, the system generates an HTML block page that includes:

\begin{lstlisting}[language=HTML, caption=Block Page Template]
def generate_block_page(url, host, confidence, detected_patterns, bypass_token):
    """Generate HTML block page for detected threats"""
    block_html = f"""
    <html>
    <head>
        <title>Warning: Potential Phishing Site Detected</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 0; padding: 0; 
                   background-color: #f8f9fa; }}
            .container {{ max-width: 800px; margin: 50px auto; padding: 30px; 
                         background-color: white; border-radius: 5px; 
                         box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            h1 {{ color: #d9534f; }}
            .btn {{ display: inline-block; padding: 10px 20px; margin-right: 10px;
                  text-decoration: none; border-radius: 4px; font-weight: bold; }}
            .btn-danger {{ background-color: #d9534f; color: white; }}
            .btn-safe {{ background-color: #5cb85c; color: white; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Warning: Potential Phishing Site Detected</h1>
            <p>Our security system has identified <strong>{host}</strong> 
               as a potential phishing website with {confidence:.1f}% confidence.</p>
            
            <h3>Detection Details:</h3>
            <ul>
                <!-- List detected patterns -->
            </ul>
            
            <div class="actions">
                <a href="javascript:history.back()" class="btn btn-safe">
                    Go Back (Recommended)
                </a>
                <a href="/bypass?token={bypass_token}" class="btn btn-danger">
                    Proceed Anyway (Not Recommended)
                </a>
            </div>
            
            <p><small>This site was blocked by Smart Proxy Phishing Scanner.</small></p>
        </div>
    </body>
    </html>
    """
    return block_html
\end{lstlisting}

\section{Web Application Integration}

The Flask web application provides a user interface for manual URL scanning and whitelist management:

\begin{lstlisting}[language=Python, caption=Scanner Web Application]
app = Flask(__name__)

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/scan', methods=['POST'])
def scan_url():
    url = request.form.get('url', '').rstrip('/')
    
    if not url:
        return jsonify({'error': 'URL is required'}), 400
        
    try:
        # Fetch HTML content
        response = requests.get(url, timeout=5)
        html_content = response.text
        
        # Perform ML detection
        is_phishing, confidence, ml_time = ml_detector.predict(url, html_content)
        
        # Perform traditional analysis
        traditional_result = traffic_analyzer.analyze(url, html_content)
        
        # Combine results
        result = {
            'url': url,
            'is_malicious': is_phishing or traditional_result['is_malicious'],
            'ml_detection': {
                'is_phishing': is_phishing,
                'confidence': confidence,
                'analysis_time_ms': ml_time
            },
            'traditional_detection': traditional_result,
            'timestamp': time.time()
        }
        
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500
\end{lstlisting}

\section{Whitelist Management Interface}

A dedicated web interface for whitelist management provides CRUD operations:

\begin{lstlisting}[language=Python, caption=Whitelist Management Routes]
@app.route('/whitelist')
def whitelist_manager():
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 50, type=int)
    search = request.args.get('search', '')
    
    # Convert whitelist set to a sorted list for pagination
    whitelist = list(sorted(traffic_analyzer.whitelist))
    
    # Filter by search term if provided
    if search:
        whitelist = [domain for domain in whitelist 
                    if search.lower() in domain.lower()]
    
    # Calculate pagination values
    total_items = len(whitelist)
    total_pages = math.ceil(total_items / per_page)
    start_idx = (page - 1) * per_page
    end_idx = min(start_idx + per_page, total_items)
    current_items = whitelist[start_idx:end_idx]
    
    return render_template('whitelist.html', 
                          domains=current_items, 
                          page=page, 
                          per_page=per_page, 
                          total_pages=total_pages,
                          total_items=total_items,
                          search=search)
\end{lstlisting}
